# Master's Thesis
This is a repository for the final project of my Master's in Computational Social Sciences. The project explores the use of large language models as automatic annotators for hate speech detection. The focus is not on testing the models' accuracy, but on exploring disagreement between the models. Disagreement is here understood as a potentially valuable signal, a proxy for ambiguity, complexity or subjectivity in the input text, rather than as noise or error. My goal is to better understand LLMs and how researchers might make the best use of them as annotators for social sciences data.
